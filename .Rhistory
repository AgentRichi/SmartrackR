urls <- paste("http://www.realestate.com.au/buy/in-docklands%2c+vic+3008%3b+melbourne%2c+vic+3000%3b+southbank%2c+vic+3006%3b+brunswick%2c+vic+3056%3b+brunswick+east%2c+vic+3057%3b+carlton%2c+vic+3053%3b+carlton+north%2c+vic+3054%3b+clifton+hill%2c+vic+3068%3b+collingwood%2c+vic+3066%3b+fitzroy%2c+vic+3065%3b+fitzroy+north%2c+vic+3068%3b+north+melbourne%2c+vic+3051%3b+northcote%2c+vic+3070%3b+parkville%2c+vic+3052%3b+princes+hill%2c+vic+3054%3b+abbotsford%2c+vic+3067%3b+burnley%2c+vic+3121%3b+cremorne%2c+vic+3121%3b+east+melbourne%2c+vic+3002%3b+prahran%2c+vic+3181%3b+richmond%2c+vic+3121%3b+south+yarra%2c+vic+3141%3b+hawthorn%2c+vic+3122%3b+albert+park%2c+vic+3206%3b+middle+park%2c+vic+3206%3b+port+melbourne%2c+vic+3207%3b+south+melbourne%2c+vic+3205%3b+flemington%2c+vic+3031%3b+kensington%2c+vic+3031%3b+travancore%2c+vic+3032%3b+west+melbourne%2c+vic+3003%3b/list-",x,"?includeSurrounding=false",sep="")
pbsapply(urls, function(z){
read_html(z) %>% html_nodes(".name") %>% html_attr("href")
})
})
#USING RVEST
library(rvest)
library(data.table)
library(magrittr)
library(pbapply)
library(curl)
#Need to find a way to determine number of pages to scrape
pages <- read_html("http://www.realestate.com.au/buy/in-docklands%2c+vic+3008%3b+melbourne%2c+vic+3000%3b+southbank%2c+vic+3006%3b+brunswick%2c+vic+3056%3b+brunswick+east%2c+vic+3057%3b+carlton%2c+vic+3053%3b+carlton+north%2c+vic+3054%3b+clifton+hill%2c+vic+3068%3b+collingwood%2c+vic+3066%3b+fitzroy%2c+vic+3065%3b+fitzroy+north%2c+vic+3068%3b+north+melbourne%2c+vic+3051%3b+northcote%2c+vic+3070%3b+parkville%2c+vic+3052%3b+princes+hill%2c+vic+3054%3b+abbotsford%2c+vic+3067%3b+burnley%2c+vic+3121%3b+cremorne%2c+vic+3121%3b+east+melbourne%2c+vic+3002%3b+prahran%2c+vic+3181%3b+richmond%2c+vic+3121%3b+south+yarra%2c+vic+3141%3b+hawthorn%2c+vic+3122%3b+albert+park%2c+vic+3206%3b+middle+park%2c+vic+3206%3b+port+melbourne%2c+vic+3207%3b+south+melbourne%2c+vic+3205%3b+flemington%2c+vic+3031%3b+kensington%2c+vic+3031%3b+travancore%2c+vic+3032%3b+west+melbourne%2c+vic+3003%3b/list-1?includeSurrounding=false")
pages <- pages %>% html_nodes("#resultsInfo p") %>% html_text() %>% strsplit(split=" ")
pages <- c(1:ceiling(as.numeric(pages[[1]][6])/as.numeric(pages[[1]][4])))
urls <- sapply(pages,function(x) {
paste("http://www.realestate.com.au/buy/in-docklands%2c+vic+3008%3b+melbourne%2c+vic+3000%3b+southbank%2c+vic+3006%3b+brunswick%2c+vic+3056%3b+brunswick+east%2c+vic+3057%3b+carlton%2c+vic+3053%3b+carlton+north%2c+vic+3054%3b+clifton+hill%2c+vic+3068%3b+collingwood%2c+vic+3066%3b+fitzroy%2c+vic+3065%3b+fitzroy+north%2c+vic+3068%3b+north+melbourne%2c+vic+3051%3b+northcote%2c+vic+3070%3b+parkville%2c+vic+3052%3b+princes+hill%2c+vic+3054%3b+abbotsford%2c+vic+3067%3b+burnley%2c+vic+3121%3b+cremorne%2c+vic+3121%3b+east+melbourne%2c+vic+3002%3b+prahran%2c+vic+3181%3b+richmond%2c+vic+3121%3b+south+yarra%2c+vic+3141%3b+hawthorn%2c+vic+3122%3b+albert+park%2c+vic+3206%3b+middle+park%2c+vic+3206%3b+port+melbourne%2c+vic+3207%3b+south+melbourne%2c+vic+3205%3b+flemington%2c+vic+3031%3b+kensington%2c+vic+3031%3b+travancore%2c+vic+3032%3b+west+melbourne%2c+vic+3003%3b/list-",x,"?includeSurrounding=false",sep="")
})
addresses <- pbsapply(urls, function(x) {
loc <- read_html(x)
loc %>% html_nodes(".name") %>% html_text()
})
#joblocations <- data.frame(table(unlist(jobLocations))) %>% setorder(-Freq)
#Find nex URL to crawl
links <- pbsapply(pages, function(x){
urls <- paste("http://www.realestate.com.au/buy/in-docklands%2c+vic+3008%3b+melbourne%2c+vic+3000%3b+southbank%2c+vic+3006%3b+brunswick%2c+vic+3056%3b+brunswick+east%2c+vic+3057%3b+carlton%2c+vic+3053%3b+carlton+north%2c+vic+3054%3b+clifton+hill%2c+vic+3068%3b+collingwood%2c+vic+3066%3b+fitzroy%2c+vic+3065%3b+fitzroy+north%2c+vic+3068%3b+north+melbourne%2c+vic+3051%3b+northcote%2c+vic+3070%3b+parkville%2c+vic+3052%3b+princes+hill%2c+vic+3054%3b+abbotsford%2c+vic+3067%3b+burnley%2c+vic+3121%3b+cremorne%2c+vic+3121%3b+east+melbourne%2c+vic+3002%3b+prahran%2c+vic+3181%3b+richmond%2c+vic+3121%3b+south+yarra%2c+vic+3141%3b+hawthorn%2c+vic+3122%3b+albert+park%2c+vic+3206%3b+middle+park%2c+vic+3206%3b+port+melbourne%2c+vic+3207%3b+south+melbourne%2c+vic+3205%3b+flemington%2c+vic+3031%3b+kensington%2c+vic+3031%3b+travancore%2c+vic+3032%3b+west+melbourne%2c+vic+3003%3b/list-",x,"?includeSurrounding=false",sep="")
sapply(urls, function(z){
read_html(z) %>% html_nodes(".name") %>% html_attr("href")
})
})
links2 <- unlist(links)
data <- list()
for (i in seq(1,length(links2)-ceiling(length(links2)/10),by=ceiling(length(links2)/10))) {
addresses2 <- pbsapply(links2[i:(i+ceiling(length(links2)/10))], function(x) {
newad <- read_html(curl(paste("http://www.realestate.com.au",x,sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
data <- c(data, newad)
})
}
data <- list()
data <- list()
for (i in seq(1,100,by=10)) {
addresses2 <- ppbsaply(links2[i:(i+9)], function(x) {
newad <- read_html(curl(paste("http://www.realestate.com.au",x,sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
})
data <- c(data, addresses2)
}
for (i in seq(1,100,by=10)) {
addresses2 <- pbsapply(links2[i:(i+9)], function(x) {
newad <- read_html(curl(paste("http://www.realestate.com.au",x,sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
})
data <- c(data, addresses2)
}
data
data <- setNames(data.frame(do.call(rbind,lapply(1:length(addresses),function(i)t(addresses[[i]][1:4])))),c("Street","Suburb","State","Postcode"))
data
View(data)
data <- list()
for (i in seq(1,100,by=10)) {
addresses2 <- pbsapply(links2[i:(i+9)], function(x) {
newad <- read_html(curl(paste("http://www.realestate.com.au",x,sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
})
data <- c(data, addresses2)
}
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(addresses[[i]][1])))),c("Address"))
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(addresses[[i]][1:1])))),c("Address"))
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(addresses[[i]][1:4])))),c("Street","Suburb","State","Postcode"))
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(data[[i]][1])))),c("Street"))
View(data2)
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(data[[i]][1:4])))),c("Street","Suburb","State","Postcode"))
View(data2)
data <- vector("list",109)
data <- vector("list",109)
for (i in seq(1,100,by=10)) {
pbsapply(links2[i:(i+9)], function(x) {
data[[i]] <- read_html(curl(paste("http://www.realestate.com.au",x,sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
})
}
data <- vector("list",100)
for (i in seq(1,100,by=1)) {
data[[i]] <- read_html(curl(paste("http://www.realestate.com.au",links2[i],sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
}
View(data2)
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(data[[i]][1:4])))),c("Street","Suburb","State","Postcode"))
View(data2)
links2[1:100]
data <- pbsapply(links2[1:100], function(i){
read_html(curl(paste("http://www.realestate.com.au",i,sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
})
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(data[[i]][1:4])))),c("Street","Suburb","State","Postcode"))
View(data2)
data <- vector("list",length = length(links2))
data <- pbsapply(links2, function(i){
read_html(curl(paste("http://www.realestate.com.au",i,sep = ""),handle = curl::new_handle("useragent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"))) %>% html_nodes("h1 span") %>% html_text()
})
data2 <- setNames(data.frame(do.call(rbind,lapply(1:length(data),function(i)t(data[[i]][1:4])))),c("Street","Suburb","State","Postcode"))
View(data2)
View(data2)
rm(list=ls(all=TRUE))
library(dplyr)
library(data.table)
library(magrittr)
library(lubridate)
library(xlsx)
work_dir <- "C:/Data/Smartrack/"
setwd(paste0(work_dir, "./Data/"))
# Load the data
tfv_file <- list.files()
buses <- data.frame()
?read.xlsx
tst <- read.xlsx(tfv_file[1], header = TRUE,stringsAsFactors = F, startRow = 4)
tst <- read.xlsx(tfv_file[1], sheetIndex = 1, header = TRUE,stringsAsFactors = F, startRow = 4)
View(tst)
rm(list=ls(all=TRUE))
library(dplyr)
library(data.table)
library(magrittr)
library(lubridate)
library(xlsx)
work_dir <- "C:/Data/Smartrack/"
setwd(paste0(work_dir, "./Data/"))
# Load the data
tfv_file <- list.files()
buses <- data.frame()
for(i in 1:length(tfv_file))
{
buses <- rbind(buses,
read.csv(tfv_file[i], header = TRUE,stringsAsFactors = F, skip=0))
}
setwd(work_dir)
rm(list=ls(all=TRUE))
library(dplyr)
library(data.table)
library(magrittr)
library(lubridate)
library(xlsx)
work_dir <- "C:/Data/Smartrack/"
setwd(paste0(work_dir, "./Data/"))
# Load the data
tfv_file <- list.files()
buses <- data.frame()
for(i in 1:length(tfv_file))
{
buses <- rbind(buses,
read.csv(tfv_file[i], header = TRUE,stringsAsFactors = F, skip=0))
}
setwd(work_dir)
View(buses)
rm(list=ls(all=TRUE))
library(dplyr)
library(data.table)
library(magrittr)
library(lubridate)
library(xlsx)
work_dir <- "C:/Data/Smartrack/"
setwd(paste0(work_dir, "./Data/"))
# Load the data
tfv_file <- list.files()
buses <- data.frame()
for(i in 1:length(tfv_file))
{
buses <- rbind(buses,
read.csv(tfv_file[i], header = TRUE,stringsAsFactors = F, skip=0))
}
setwd(work_dir)
# buses <- read.csv("C://Data/Smartrack/Data/TFV - CTD_13062018.csv", header = T, stringsAsFactors = F) %>% as.tbl()
# validLegs <- read.csv("C://Data/Smartrack/ValidLegs.csv", stringsAsFactors = F)
buses <- buses %>% filter(Geofence.Name != "")
#Enter.Time is in a different format when dowloading directly compared to converting from xlsx
# for csv direct download use as.POSIXct(strptime(gsub('[\\.]','',Enter.Time), format = '%d/%m/%Y %H:%M'))
# for converted csv use as.POSIXct(Enter.Time), format = '%d/%m/%Y %I:%M:%S %p'
# format arrival time and separate geofence name into columns, then order by bus and timestamp
buses <- buses %>% mutate(arrival = as.POSIXct(strptime(gsub('[\\.]','',Enter.Time), format = '%d/%m/%Y %I:%M:%S %p')),
project = unlist(lapply(strsplit(Geofence.Name," - "),'[[',2)),
stop.order = as.numeric(unlist(lapply(strsplit(Geofence.Name," - "),'[[',3))),
destination = unlist(lapply(strsplit(Geofence.Name," - "),'[[',4))) %>%
arrange(Resource.Name, seconds(Enter.Time))
#format dwell time into seconds
tmp <- strsplit(buses$Time.Inside.Geofence..hh.mm.ss., split=":") %>% lapply(as.numeric,1)
dwellTime <- do.call(rbind, lapply(tmp, rbind))
dwellTime <- dwellTime[,1]*60*60 + dwellTime[,2]*60 + dwellTime[,3]
buses$dwellTime <- dwellTime %>% seconds()
#calculate departure time (arrival+dwell) and get origin from preceding row
buses <- buses %>% mutate(departure = lag(dwellTime,1)+lag(arrival,1),
origin = ifelse(lag(Resource.Name,1)==Resource.Name,lag(destination,1),"0"))
buses$origin[1] <- "0"
#VALID TRIPS:
# Caulfield - Carnegie - LTD EXP Flag - Full Exp Flag - Westall
# Malvern - Carnegie - LTD EXP Flag - Oakleigh - Huntingdale - Clayton - Westall
# Caulfield - Carnegie - Murrumbeena - Hughesdale - Oakleigh - Huntingdale - Clayton - Westall
#NEW VALID TRIPS:
#Stopping all Stations (SAS): Newmarket - Ascot Vale - Moonee Ponds - Essendon
#Limited Express (LTD EXP): Flemington Racecourse - Essendon - Glenbervie - Strathmore - Pascoe Vale - Oak Park - Glenroy - Broadmeadows
#Express (EXP): Flemington Racecourse - EXP Flag - Broadmeadows
#CRAN-PAK Pt1
# SAS: Dandenong - Hallam - Narre Warren - Berwick - Beaconsfield - Officer - Cardinia Road - Pakenham
# SAS_Cran: Dandenong - Lynbrook - Merinda Park - Cranbourne
# Ltd Exp: Dandenong - Berwick - Beaconsfield - Officer - Cardinia Road - Pakenham
# Exp: Dandenong - Pakenham
express <- c("Dandenong","Pakenham") #-1
# express_2 <- c("Flemington","Newmarket","Full Exp Flag","Broadmeadows") #-1
ltd_express <- c("Dandenong","Berwick","Beaconsfield","Officer","Cardinia Road","Pakenham") #-2
sas_Pak <- c("Dandenong","Hallam","Narre Warren","Berwick","Beaconsfield","Officer","Cardinia Road","Pakenham") #+4
sas <- c("Dandenong","Lynbrook","Merinda Park","Cranbourne") #0
#Variables for while loop
stops <- 1
buses$type <- c(rep(0,length(buses$Resource.Name)))
buses$direction <- c(rep(0,length(buses$Resource.Name)))
#Iterate to assign bus type based on stopping pattern
############
#ISSUE!!: Currently if a bus enters/exits the same geofence more than once (happening at Oakleigh) -
#the trip is filtered out, even though it might be a legitimate replacement bus
############
while(stops < length(buses$origin)) {
org = buses$origin
dest = buses$destination
#EXPRESS BUS
if (
(org[stops] == first(express) && dest[stops] == last(express))
)
{
buses$type[stops:(stops+length(express)-2)] <- "PAK Express"
buses$direction[stops:(stops+length(express)-2)] <- "up"
stops <- stops+length(express)-1
}
else if (
(org[stops] == last(express) && dest[stops] == first(express))
)
{
buses$type[stops:(stops+length(express)-2)] <- "PAK Express"
buses$direction[stops:(stops+length(express)-2)] <- "up"
stops <- stops+length(express)-1
}
#LTD EXPRESS BUS
else if (
(org[stops] == first(ltd_express) && dest[stops] == ltd_express[2]) &&
(lead(org,1)[stops] == ltd_express[2] && lead(dest,1)[stops] == ltd_express[3]) &&
(lead(org,2)[stops] == ltd_express[3] && lead(dest,2)[stops] == ltd_express[4]) &&
(lead(org,3)[stops] == ltd_express[4] && lead(dest,3)[stops] == ltd_express[5]) &&
(lead(org,4)[stops] == ltd_express[5] && lead(dest,4)[stops] == last(ltd_express))
)
{
buses$type[stops:(stops+length(ltd_express)-2)] <- "PAK LTD Express"
buses$direction[stops:(stops+length(ltd_express)-2)] <- "down"
stops <- stops+length(ltd_express)-1
}
else if ( #last = 6
(org[stops] == last(ltd_express) && dest[stops] == ltd_express[5]) &&
(lead(org,1)[stops] == ltd_express[5] && lead(dest,1)[stops] == ltd_express[4]) &&
(lead(org,2)[stops] == ltd_express[4] && lead(dest,2)[stops] == ltd_express[3]) &&
(lead(org,3)[stops] == ltd_express[3] && lead(dest,3)[stops] == ltd_express[2]) &&
(lead(org,4)[stops] == ltd_express[2] && lead(dest,4)[stops] == first(ltd_express))
)
{
buses$type[stops:(stops+length(ltd_express)-2)] <- "PAK LTD Express"
buses$direction[stops:(stops+length(ltd_express)-2)] <- "up"
stops <- stops+length(ltd_express)-1
}
#SAS CRAN
else if (
(org[stops] == first(sas) && dest[stops] == sas[2]) &&
(lead(org,1)[stops] == sas[2] && lead(dest,1)[stops] == sas[3]) &&
(lead(org,2)[stops] == sas[3] && lead(dest,2)[stops] == sas[4])
)
{
buses$type[stops:(stops+length(sas)-2)] <- "CRAN SAS"
buses$direction[stops:(stops+length(sas)-2)] <- "down"
stops <- stops+length(sas)-1
}
else if ( #last = 4
(org[stops] == last(sas) && dest[stops] == sas[3]) &&
(lead(org,1)[stops] == sas[3] && lead(dest,1)[stops] == sas[2]) &&
(lead(org,2)[stops] == sas[2] && lead(dest,2)[stops] == sas[1])
)
{
buses$type[stops:(stops+length(sas)-2)] <- "CRAN SAS"
buses$direction[stops:(stops+length(sas)-2)] <- "up"
stops <- stops+length(sas)-1
}
#SAS PAK
else if (
(org[stops] == first(sas_Pak) && dest[stops] == sas_Pak[2]) &&
(lead(org,1)[stops] == sas_Pak[2] && lead(dest,1)[stops] == sas_Pak[3]) &&
(lead(org,2)[stops] == sas_Pak[3] && lead(dest,2)[stops] == sas_Pak[4]) &&
(lead(org,3)[stops] == sas_Pak[4] && lead(dest,3)[stops] == sas_Pak[5]) &&
(lead(org,4)[stops] == sas_Pak[5] && lead(dest,4)[stops] == sas_Pak[6]) &&
(lead(org,5)[stops] == sas_Pak[6] && lead(dest,5)[stops] == sas_Pak[7]) &&
(lead(org,5)[stops] == sas_Pak[7] && lead(dest,6)[stops] == last(sas_Pak))
)
{
buses$type[stops:(stops+length(sas_Pak)-2)] <- "PAK SAS"
buses$direction[stops:(stops+length(sas_Pak)-2)] <- "down"
stops <- stops+length(sas_Pak)-1
}
else if ( #last = 8
(org[stops] == last(sas_Pak) && dest[stops] == sas_Pak[7]) &&
(lead(org,1)[stops] == sas_Pak[7] && lead(dest,1)[stops] == sas_Pak[6]) &&
(lead(org,2)[stops] == sas_Pak[6] && lead(dest,2)[stops] == sas_Pak[5]) &&
(lead(org,3)[stops] == sas_Pak[5] && lead(dest,3)[stops] == sas_Pak[4]) &&
(lead(org,4)[stops] == sas_Pak[4] && lead(dest,4)[stops] == sas_Pak[3]) &&
(lead(org,5)[stops] == sas_Pak[3] && lead(dest,5)[stops] == sas_Pak[2]) &&
(lead(org,6)[stops] == sas_Pak[2] && lead(dest,6)[stops] == first(sas_Pak))
)
{
buses$type[stops:(stops+length(sas_Pak)-2)] <- "PAK SAS"
buses$direction[stops:(stops+length(sas_Pak)-2)] <- "up"
stops <- stops+length(sas_Pak)-1
}
else {
buses$type[stops] <- "None"
stops <- stops+1
}
}
#remove non RRP Buses and unnecessary columns
railRep <- buses %>% filter(!(type %in% c("None",0))) %>%
select(project,Resource.Name,Registration,type,direction,origin,destination,departure,arrival,dwellTime)
#variables needed to work out trip ID
Pak_startpoints <- c("Dandenong","Pakenham")
Cran_startpoints <- c("Dandenong","Cranbourne")
railRep$tripId <- c(rep(0,length(railRep$Resource.Name)))
id = 0
# logic: if there is no origin (i.e. this is the first data point for the bus) OR
# if the origin is a startpoint, then the leg is part of a new trip
for(leg in seq(1,length(railRep$origin))) {
if(railRep$type[leg] == "CRAN SAS" & railRep$origin[leg] %in% Cran_startpoints) {
id = id+1
railRep$tripId[leg] <- id
} else if(railRep$type[leg] != "CRAN SAS" & railRep$origin[leg] %in% Pak_startpoints) {
id = id+1
railRep$tripId[leg] <- id
} else {
railRep$tripId[leg] <- id
}
}
# ifelse(
#   (railRep$type == "SAS" & railRep$origin %in% sas_startpoints),
#   id+1, ifelse(
#     railRep$type != "SAS" & railRep$origin %in% startpoints,
#     id+1, id
#   )
# )
# Determine the peak time
tripArrival <- railRep %>% filter(!duplicated(tripId)) %>%
select(tripId,arrival) %>% mutate(tripArrival = hour(arrival)) %>%
select(tripId,tripArrival)
railRep <- railRep %>% left_join(tripArrival,"tripId")
railRep <- railRep %>% mutate(peak = sapply(tripArrival,function(x){
if(x>6 & x<9){"AM Peak"}
else if (x>8 & x<16){"Intra Peak"}
else if (x>15 & x<19){"PM Peak"}
else {"Off Peak"}
}))
# if the destination OR origin is a start/end point then dwelltime = 0, else dwelltime/60 to get minutes
#NOTE this is not entirely accurate, but to check dwell times at start/end, we need more validation
#to ensure the bus was not sitting idle and actually picking up/dropping off passengers
for(i in seq(1:length(railRep$dwellTime))) {
if (
((railRep$destination[i] %in% Cran_startpoints || railRep$origin[i] %in% Cran_startpoints)) ||
((railRep$destination[i] %in% Pak_startpoints || railRep$origin[i] %in% Pak_startpoints))
)
{
railRep$dwellAdj[i] <- 0
} else {railRep$dwellAdj[i] <- railRep$dwellTime[i]/60}
}
# ##
# #REMOVE EXPRESS FLAGS
# ##
#
# #Step 1: separate express buses
# exp_buses <- data.table(railRep[railRep$type=="Express",c("origin",
#                                                           "destination",
#                                                           "departure",
#                                                           "arrival",
#                                                           "tripId",
#                                                           "dwellAdj")],
#                         key = "tripId")
#
# #Step 2: For each trip, select org and dest, and sum up travel time
# exp_buses <- exp_buses[,list(
#   origin=first(origin),
#   destination=last(destination),
#   departure=first(departure),
#   arrival=last(arrival),
#   dwellAdj=sum(dwellAdj)),by=tripId] %>%
#
# #Step 3: join other columns from railrep table
#   left_join(railRep[,c("project",
#                        "Resource.Name",
#                        "Registration",
#                        "type",
#                        "tripId",
#                        "origin",
#                        "tripDeparture",
#                        "peak")],
#               by = c("tripId","origin"))
#
# #Step 4: Combine express buses with other buses
# railRep <- rbind(railRep[railRep$type != "Express",names(railRep) !="dwellTime"],exp_buses)
# ifelse((
# (railRep$destination %in% startpoints && railRep$type !="SAS")
# ||
# (railRep$origin %in% sas_startpoints && railRep$type == "SAS")),
# 0, railRep$dwellTime/60)
# travel_times <- railRep %>%
#   filter(difftime(arrival,departure, tz = "AEST", units = "mins") < 50,
#          !(tripId %in% c(77,127))) %>%
#   group_by(tripId, type, peak) %>%
#   summarise(TripTime = sum(difftime(arrival,departure, tz = "AEST", units = "mins")+dwellAdj))
# travel_times <- travel_times %>% group_by(type, peak) %>%
#   summarise(TravelTimes = mean(TripTime))
# write.csv(travel_times,paste0("test2.csv"))
# write.csv(travel_times,paste0("CTD Bus Travel Times - ",date(Sys.time()-days(1)),".csv"))
###TO DO:
#Add dwell times to total JT - Done
#Calculate time for each leg of journey - Done but need to deal with express flags
leg_times <- railRep %>%
group_by(tripId, direction, origin, destination, peak, type, departure, arrival,dwellAdj) %>%
summarise(TripTime = sum(difftime(arrival,departure, tz = "AEST", units = "mins")+dwellAdj)) %>%
filter(date(departure) == date(arrival))
# leg_times <- leg_times %>% group_by(origin,destination, peak, type) %>%
#  summarise(TravelTimes = mean(TripTime))
# write.csv(leg_times,paste0("Output/CRANPAK Bus Leg Times - ",date(Sys.time()-days(1)),".csv"), row.names = F)
merge_times <- merge(leg_times, railRep, by = c("tripId","type","direction","peak","departure","arrival","origin","destination","dwellAdj"), all.x = T)
merge_times <- cbind("VCDI_ID" = sprintf("VCDI_ID_%06d", 1:nrow(merge_times)), merge_times)
merge_times$tripId <- as.character(merge_times$tripId)
# Validation
tripTime_check <- subset(merge_times, merge_times$TripTime >= 30)
merge_times <- merge_times[c( "VCDI_ID"
,"tripId"
,"project"
,"Resource.Name"
,"Registration"
,"departure"
,"arrival"
,"type"
,"direction"
,"peak"
,"origin"
,"destination"
,"dwellAdj"
,"TripTime"
)]
# write.csv(merge_times,paste0("Output/","CRANPAK Bus Leg Times.csv"), row.names = F)
# Total Travel Time
travel_times <- railRep %>%
filter(date(departure) == date(arrival), type != "0") %>%
# !(tripId %in% c(77,127))
group_by(tripId, type, direction, peak, Resource.Name, date(departure)) %>%
summarise(Origin = first(origin), Destination = last(destination),
Departure = first(departure), Arrival = last(arrival),
TripTime = sum(difftime(arrival,departure, tz = "AEST", units = "mins")+dwellAdj)) %>%
filter(TripTime < 100)
journey_times <- travel_times %>% group_by(type, peak, direction) %>%
summarise(TravelTimes = mean(TripTime),
NumBuses = n())
# write.csv(travel_times,paste0("Output/","CRANPAK Bus Trip Times.csv"), row.names = F)
# write.csv(journey_times,paste0("Output/","CRANPAK Bus Journey Times.csv"), row.names = F)
View(journey_times)
View(travel_times)
View(travel_times)
View(railRep)
View(buses)
View(leg_times)
?summarise
edges <- leg_times %>% select(from=origin,to=destination,TripTime) %>%
summarise(weight=mean(TripTime)) %>%
group_by(from,to)
View(edges)
library(magrittr)
edges <- leg_times %>% select(from=origin,to=destination,TripTime) %>%
summarise(weight=mean(TripTime)) %>%
group_by(from,to)
edges <- leg_times %>% select(from=origin,to=destination,TripTime)
edges <- leg_times %>% group_by(origin,estination,TripTime) %>%
summarise(weight=mean(TripTime))
edges <- leg_times %>% group_by(origin,destination,TripTime) %>%
summarise(weight=mean(TripTime))
View(edges)
edges <- leg_times %>% group_by(origin,destination) %>%
summarise(weight=mean(TripTime))
install.packages("igraph")
library(magrittr)
library(igraph)
edges <- leg_times %>% group_by(origin,destination) %>%
summarise(weight=mean(TripTime))
?graph_from_data_frame
routes_igraph <- graph_from_data_frame(d = edges, directed = TRUE)
routes_igraph
plot(routes_igraph, edge.arrow.size = 0.2)
lot(routes_igraph, layout = layout_with_graphopt, edge.arrow.size = 0.2)
plot(routes_igraph, layout = layout_with_graphopt, edge.arrow.size = 0.2)
install.packages("ggraph")
library(magrittr)
library(ggraph)
edges <- leg_times %>% group_by(origin,destination) %>%
summarise(weight=mean(TripTime))
routes_igraph <- graph_from_data_frame(d = edges, directed = TRUE)
ggraph(routes_igraph, layout = "linear") +
geom_edge_arc(aes(width = weight), alpha = 0.8) +
scale_edge_width(range = c(0.2, 2)) +
geom_node_text(aes(label = label)) +
labs(edge_width = "Letters") +
theme_graph()
library(ggplot2)
library(ggraph)
install.packages("units")
library(magrittr)
library(ggplot2)
library(ggraph)
library(ggraph)
devtools::install_github('hadley/ggplot2')
devtools::install_github('thomasp85/ggforce')
devtools::install_github('thomasp85/ggraph')
